{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization & Advanced Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Symptom_1</th>\n",
       "      <th>Symptom_2</th>\n",
       "      <th>Symptom_3</th>\n",
       "      <th>Symptom_4</th>\n",
       "      <th>Symptom_5</th>\n",
       "      <th>Symptom_6</th>\n",
       "      <th>Symptom_7</th>\n",
       "      <th>Symptom_8</th>\n",
       "      <th>Symptom_9</th>\n",
       "      <th>Symptom_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Disease  Symptom_1  Symptom_2  Symptom_3  Symptom_4  Symptom_5  Symptom_6  \\\n",
       "0       15          0          1         34         55         14         42   \n",
       "1       15          1         34         55         33         14         42   \n",
       "2       15          0         34         55         33         14         42   \n",
       "3       15          0          1         55         33         14         42   \n",
       "4       15          0          1         34         33         14         42   \n",
       "\n",
       "   Symptom_7  Symptom_8  Symptom_9  Symptom_10  \n",
       "0         43         43         79          79  \n",
       "1         43         43         79          79  \n",
       "2         43         43         79          79  \n",
       "3         43         43         79          79  \n",
       "4         43         43         79          79  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Datasets/final_dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:].values\n",
    "y = dataset['Disease'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the features for SVM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "X_train_scaled = scalar.fit_transform(X_train)\n",
    "X_test_scaled = scalar.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(model, param_grid, X, y, cv=5, search='grid'):\n",
    "    if search == 'grid':\n",
    "        searcher = GridSearchCV(model, param_grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    elif search == 'random':\n",
    "        searcher = RandomizedSearchCV(model, param_grid, scoring='accuracy', cv=cv, n_jobs=-1, n_iter=50)\n",
    "    searcher.fit(X, y)\n",
    "    return searcher.best_estimator_, searcher.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PRANAV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(multi_class='ovr', solver='liblinear', random_state=42)\n",
    "log_model.fit(X_train, y_train)\n",
    "log_y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {'n_neighbors': range(3, 10), 'metric': ['minkowski'], 'p': [1, 2]}\n",
    "knn_model, knn_best_params = tune_model(KNeighborsClassifier(), knn_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {'C': [0.1, 1, 10]}\n",
    "svm_model, svm_best_params = tune_model(SVC(kernel='linear', random_state=42), svm_params, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernal SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernal_svm_params = {'C': [1, 10, 100], 'gamma': [0.001, 0.01, 0.1]}\n",
    "kernal_svm_model, kernal_svm_best_params = tune_model(SVC(kernel='rbf', random_state=42), kernal_svm_params, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_y_pred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {'max_depth': range(3, 15), 'min_samples_split': [2, 5, 10]}\n",
    "dec_tree_model, dec_tree_best_params = tune_model(DecisionTreeClassifier(random_state=42), dt_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {'n_estimators': [50, 100, 200], 'max_depth': [10, 15, 20], 'min_samples_split': [2, 5, 10]}\n",
    "ran_forest_model, ran_forest_best_params = tune_model(RandomForestClassifier(random_state=42), rf_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PRANAV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:45:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]}\n",
    "xgb_model, xgb_best_params = tune_model(XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42), xgb_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 355\n",
      "[LightGBM] [Info] Number of data points in the train set: 3936, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -3.652947\n",
      "[LightGBM] [Info] Start training from score -3.778111\n",
      "[LightGBM] [Info] Start training from score -3.713572\n",
      "[LightGBM] [Info] Start training from score -3.724043\n",
      "[LightGBM] [Info] Start training from score -3.713572\n",
      "[LightGBM] [Info] Start training from score -3.703209\n",
      "[LightGBM] [Info] Start training from score -3.812012\n",
      "[LightGBM] [Info] Start training from score -3.703209\n",
      "[LightGBM] [Info] Start training from score -3.682800\n",
      "[LightGBM] [Info] Start training from score -3.623960\n",
      "[LightGBM] [Info] Start training from score -3.703209\n",
      "[LightGBM] [Info] Start training from score -3.734625\n",
      "[LightGBM] [Info] Start training from score -3.682800\n",
      "[LightGBM] [Info] Start training from score -3.767061\n",
      "[LightGBM] [Info] Start training from score -3.713572\n",
      "[LightGBM] [Info] Start training from score -3.662800\n",
      "[LightGBM] [Info] Start training from score -3.756132\n",
      "[LightGBM] [Info] Start training from score -3.724043\n",
      "[LightGBM] [Info] Start training from score -3.703209\n",
      "[LightGBM] [Info] Start training from score -3.745321\n",
      "[LightGBM] [Info] Start training from score -3.734625\n",
      "[LightGBM] [Info] Start training from score -3.703209\n",
      "[LightGBM] [Info] Start training from score -3.767061\n",
      "[LightGBM] [Info] Start training from score -3.724043\n",
      "[LightGBM] [Info] Start training from score -3.713572\n",
      "[LightGBM] [Info] Start training from score -3.734625\n",
      "[LightGBM] [Info] Start training from score -3.682800\n",
      "[LightGBM] [Info] Start training from score -3.713572\n",
      "[LightGBM] [Info] Start training from score -3.662800\n",
      "[LightGBM] [Info] Start training from score -3.692953\n",
      "[LightGBM] [Info] Start training from score -3.724043\n",
      "[LightGBM] [Info] Start training from score -3.692953\n",
      "[LightGBM] [Info] Start training from score -3.713572\n",
      "[LightGBM] [Info] Start training from score -3.643191\n",
      "[LightGBM] [Info] Start training from score -3.756132\n",
      "[LightGBM] [Info] Start training from score -3.692953\n",
      "[LightGBM] [Info] Start training from score -3.724043\n",
      "[LightGBM] [Info] Start training from score -3.662800\n",
      "[LightGBM] [Info] Start training from score -3.734625\n",
      "[LightGBM] [Info] Start training from score -3.692953\n",
      "[LightGBM] [Info] Start training from score -3.823573\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {'num_leaves': [31, 50, 70], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [50, 100, 200]}\n",
    "lgb_model, lgb_best_params = tune_model(LGBMClassifier(random_state=42), lgb_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models\n",
    "### Function to calculate and print evaluation metrics for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_test, y_pred, model_name):\n",
    "    print(f\"\\n{model_name} Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Evaluation Metrics:\n",
      "Accuracy: 0.8404\n",
      "Precision: 0.8597\n",
      "Recall: 0.8404\n",
      "F1 Score: 0.8423\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0 ...  0  0  0]\n",
      " [ 0 20  0 ...  0  0  0]\n",
      " [ 0  0 20 ...  2  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 26  0  0]\n",
      " [ 0  0  0 ...  0 19  0]\n",
      " [ 0  0  0 ...  0  0 28]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, log_y_pred, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Nearest Neighbors Evaluation Metrics:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Confusion Matrix:\n",
      "[[18  0  0 ...  0  0  0]\n",
      " [ 0 30  0 ...  0  0  0]\n",
      " [ 0  0 24 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 26  0  0]\n",
      " [ 0  0  0 ...  0 22  0]\n",
      " [ 0  0  0 ...  0  0 34]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, knn_model.predict(X_test), \"K-Nearest Neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM (Linear Kernel) Evaluation Metrics:\n",
      "Accuracy: 0.9787\n",
      "Precision: 0.9811\n",
      "Recall: 0.9787\n",
      "F1 Score: 0.9789\n",
      "Confusion Matrix:\n",
      "[[16  0  0 ...  0  0  0]\n",
      " [ 0 26  0 ...  0  0  0]\n",
      " [ 0  0 23 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 26  0  0]\n",
      " [ 0  0  0 ...  0 19  0]\n",
      " [ 0  0  0 ...  0  0 34]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, svm_model.predict(X_test_scaled), \"SVM (Linear Kernel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM (RBF Kernel) Evaluation Metrics:\n",
      "Accuracy: 0.9990\n",
      "Precision: 0.9990\n",
      "Recall: 0.9990\n",
      "F1 Score: 0.9990\n",
      "Confusion Matrix:\n",
      "[[18  0  0 ...  0  0  0]\n",
      " [ 0 30  0 ...  0  0  0]\n",
      " [ 0  0 24 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 26  0  0]\n",
      " [ 0  0  0 ...  0 22  0]\n",
      " [ 0  0  0 ...  0  0 34]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, kernal_svm_model.predict(X_test_scaled), \"SVM (RBF Kernel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Evaluation Metrics:\n",
      "Accuracy: 0.8364\n",
      "Precision: 0.8819\n",
      "Recall: 0.8364\n",
      "F1 Score: 0.8435\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0 ...  0  0  0]\n",
      " [ 0 22  8 ...  0  0  0]\n",
      " [ 0  0 22 ...  2  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 26  0  0]\n",
      " [ 9  0  0 ...  0  9  0]\n",
      " [ 0  0  0 ...  0  0 30]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, nb_y_pred, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Evaluation Metrics:\n",
      "Accuracy: 0.9837\n",
      "Precision: 0.9863\n",
      "Recall: 0.9837\n",
      "F1 Score: 0.9841\n",
      "Confusion Matrix:\n",
      "[[16  0  0 ...  0  0  0]\n",
      " [ 0 30  0 ...  0  0  0]\n",
      " [ 0  0 24 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 26  0  0]\n",
      " [ 0  0  0 ...  0 22  0]\n",
      " [ 0  0  0 ...  0  0 29]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, dec_tree_model.predict(X_test), \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Evaluation Metrics:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Confusion Matrix:\n",
      "[[18  0  0 ...  0  0  0]\n",
      " [ 0 30  0 ...  0  0  0]\n",
      " [ 0  0 24 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 26  0  0]\n",
      " [ 0  0  0 ...  0 22  0]\n",
      " [ 0  0  0 ...  0  0 34]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, ran_forest_model.predict(X_test), \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Evaluation Metrics:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Confusion Matrix:\n",
      "[[18  0  0 ...  0  0  0]\n",
      " [ 0 30  0 ...  0  0  0]\n",
      " [ 0  0 24 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 26  0  0]\n",
      " [ 0  0  0 ...  0 22  0]\n",
      " [ 0  0  0 ...  0  0 34]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, xgb_model.predict(X_test), \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM Evaluation Metrics:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Confusion Matrix:\n",
      "[[18  0  0 ...  0  0  0]\n",
      " [ 0 30  0 ...  0  0  0]\n",
      " [ 0  0 24 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 26  0  0]\n",
      " [ 0  0  0 ...  0 22  0]\n",
      " [ 0  0  0 ...  0  0 34]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, lgb_model.predict(X_test), \"LightGBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Classifier': ['Logistic Regression', 'K-Nearest Neighbors', 'SVM (Linear Kernel)', 'SVM (RBF Kernel)',\n",
    "                   'Naive Bayes', 'Decision Tree', 'Random Forest', 'XGBoost', 'LightGBM'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, log_y_pred),\n",
    "        accuracy_score(y_test, knn_model.predict(X_test)),\n",
    "        accuracy_score(y_test, svm_model.predict(X_test_scaled)),\n",
    "        accuracy_score(y_test, kernal_svm_model.predict(X_test_scaled)),\n",
    "        accuracy_score(y_test, nb_y_pred),\n",
    "        accuracy_score(y_test, dec_tree_model.predict(X_test)),\n",
    "        accuracy_score(y_test, ran_forest_model.predict(X_test)),\n",
    "        accuracy_score(y_test, xgb_model.predict(X_test)),\n",
    "        accuracy_score(y_test, lgb_model.predict(X_test))\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM (RBF Kernel)</td>\n",
       "      <td>0.998984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.983740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM (Linear Kernel)</td>\n",
       "      <td>0.978659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.840447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.836382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Accuracy\n",
       "1  K-Nearest Neighbors  1.000000\n",
       "6        Random Forest  1.000000\n",
       "7              XGBoost  1.000000\n",
       "8             LightGBM  1.000000\n",
       "3     SVM (RBF Kernel)  0.998984\n",
       "5        Decision Tree  0.983740\n",
       "2  SVM (Linear Kernel)  0.978659\n",
       "0  Logistic Regression  0.840447\n",
       "4          Naive Bayes  0.836382"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model as a pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Pickle files/model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(xgb_model, model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
